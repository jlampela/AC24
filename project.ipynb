{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filename identifiers\n",
    "\n",
    "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "\n",
    "* Vocal channel (01 = speech, 02 = song).\n",
    "\n",
    "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "\n",
    "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "\n",
    "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "\n",
    "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "\n",
    "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = {\n",
    "    \"01\": 'neutral',\n",
    "    \"02\": 'calm',\n",
    "    \"03\": 'happy',\n",
    "    \"04\": 'sad',\n",
    "    \"05\": 'angry',\n",
    "    \"06\": 'fearful',\n",
    "    \"07\": 'disgust',\n",
    "    \"08\": 'surprised'\n",
    "}\n",
    "\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    emotions = []\n",
    "    features = []\n",
    "    for file in glob.glob(dataset_path + 'Actor_*/*.wav'):\n",
    "        emotion = extract_emotion_from_filename(os.path.basename(file))\n",
    "        feature = extract_features(file)\n",
    "        emotions.append(emotion)\n",
    "        features.append(feature)\n",
    "    return np.array(features), np.array(emotions)\n",
    "\n",
    "def extract_emotion_from_filename(filename):\n",
    "    emotion_code = filename.split('-')[2]\n",
    "    return emotion_labels[emotion_code]\n",
    "\n",
    "def pre_emphasis(audio):\n",
    "    a = [1]\n",
    "    b = [1, -0.98]\n",
    "    pre_emphasize = lfilter(b, a, audio)\n",
    "    return pre_emphasize\n",
    "\n",
    "def extract_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "\n",
    "    # Apply preemphasis filter\n",
    "    pre_emphasize = pre_emphasis(audio)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=pre_emphasize, sr=sample_rate, n_mfcc=12)\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'ravdess/'\n",
    "features, emotions = load_data(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, emotions, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'{len(X_train)} samples in training set')\n",
    "print(f'{len(X_test)} samples in testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = {\n",
    "    'SVM': SVC(kernel='poly'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metrics in results.items():\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d')\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
